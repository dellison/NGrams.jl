<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Language Modeling · NGrams.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>NGrams.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Home</a></li><li><a class="toctext" href="../ngrams/">N-Grams</a></li><li class="current"><a class="toctext" href>Language Modeling</a><ul class="internal"><li><a class="toctext" href="#Training-1">Training</a></li><li><a class="toctext" href="#Probability-and-Smoothing-1">Probability and Smoothing</a></li><li><a class="toctext" href="#Sampling-from-a-language-model-1">Sampling from a language model</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Language Modeling</a></li></ul><a class="edit-page" href="https://github.com/dellison/NGrams.jl/blob/master/docs/src/languagemodeling.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Language Modeling</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Language-Models-1" href="#Language-Models-1">Language Models</a></h1><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NGrams.LanguageModel" href="#NGrams.LanguageModel"><code>NGrams.LanguageModel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">LanguageModel(N; bos, eos, estimator=NGrams.MLE())</code></pre><p>Create an <code>N</code>-gram language model, estimating probabilities with <code>estimator</code>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/dellison/NGrams.jl/blob/cf3d7c6b4cebb0f9e23c814bd7f8d408a607c699/src/languagemodels.jl#L8-L12">source</a></section><h2><a class="nav-anchor" id="Training-1" href="#Training-1">Training</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NGrams.fit!" href="#NGrams.fit!"><code>NGrams.fit!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">NGrams.fit!(lm::LanguageModel, tokens)</code></pre><p>Train the language model by observing a sequence of tokens.</p></div></div><a class="source-link" target="_blank" href="https://github.com/dellison/NGrams.jl/blob/cf3d7c6b4cebb0f9e23c814bd7f8d408a607c699/src/languagemodels.jl#L29-L33">source</a></section><h2><a class="nav-anchor" id="Probability-and-Smoothing-1" href="#Probability-and-Smoothing-1">Probability and Smoothing</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NGrams.MLE" href="#NGrams.MLE"><code>NGrams.MLE</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">NGrams.MLE()</code></pre><p>Maximum Likelihood Estimation for n-gram language modeling.</p></div></div><a class="source-link" target="_blank" href="https://github.com/dellison/NGrams.jl/blob/cf3d7c6b4cebb0f9e23c814bd7f8d408a607c699/src/probability.jl#L10-L14">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NGrams.AddK" href="#NGrams.AddK"><code>NGrams.AddK</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">NGrams.AddK(k::Number)</code></pre><p>Add-k probability smoothing for n-gram language modeling.</p></div></div><a class="source-link" target="_blank" href="https://github.com/dellison/NGrams.jl/blob/cf3d7c6b4cebb0f9e23c814bd7f8d408a607c699/src/probability.jl#L18-L22">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NGrams.Laplace" href="#NGrams.Laplace"><code>NGrams.Laplace</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">NGrams.Laplace()</code></pre><p>Laplace (add-1) smoothing for n-gram language modeling.</p></div></div><a class="source-link" target="_blank" href="https://github.com/dellison/NGrams.jl/blob/cf3d7c6b4cebb0f9e23c814bd7f8d408a607c699/src/probability.jl#L31-L35">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NGrams.LinearInterpolation" href="#NGrams.LinearInterpolation"><code>NGrams.LinearInterpolation</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">LinearInterpolation(λ)</code></pre><p>Linear interpolation for probability smoothing in n-gram language modeling.</p></div></div><a class="source-link" target="_blank" href="https://github.com/dellison/NGrams.jl/blob/cf3d7c6b4cebb0f9e23c814bd7f8d408a607c699/src/probability.jl#L61-L65">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NGrams.AbsoluteDiscounting" href="#NGrams.AbsoluteDiscounting"><code>NGrams.AbsoluteDiscounting</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">NGrams.AbsoluteDiscounting(d::Number)</code></pre><p>Absolute discounting for n-gram language modeling.</p></div></div><a class="source-link" target="_blank" href="https://github.com/dellison/NGrams.jl/blob/cf3d7c6b4cebb0f9e23c814bd7f8d408a607c699/src/probability.jl#L43-L47">source</a></section><h2><a class="nav-anchor" id="Sampling-from-a-language-model-1" href="#Sampling-from-a-language-model-1">Sampling from a language model</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NGrams.sample" href="#NGrams.sample"><code>NGrams.sample</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">NGrams.sample([rng::AbstractRNG,] lm, [vocabulary])</code></pre><p>Sample a single token from the language model.</p></div></div><a class="source-link" target="_blank" href="https://github.com/dellison/NGrams.jl/blob/cf3d7c6b4cebb0f9e23c814bd7f8d408a607c699/src/languagemodels.jl#L68-L72">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NGrams.generate" href="#NGrams.generate"><code>NGrams.generate</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">NGrams.generate(lm, num_words=1, text_seed=[])</code></pre><p>Randomly generate <code>num_words</code> from language model.</p><p>If <code>text_seed</code> is provided, output is conditioned on that history. The seed is included in the return value and counts against <code>num_words</code>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/dellison/NGrams.jl/blob/cf3d7c6b4cebb0f9e23c814bd7f8d408a607c699/src/languagemodels.jl#L50-L57">source</a></section><footer><hr/><a class="previous" href="../ngrams/"><span class="direction">Previous</span><span class="title">N-Grams</span></a></footer></article></body></html>
